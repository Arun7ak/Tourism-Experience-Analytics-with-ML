{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR HANDLING DATAFRAME AND FOR DATA VISUALIZATION\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING THE CSV FILE\n",
    "Tourism_df = pd.read_csv(r\"D:\\TRANSACTION PROJECT\\Full Tourism Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE TABLE\n",
    "Tourism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING NULL VALUE\n",
    "Tourism_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING DUPLICATE VALUE\n",
    "Tourism_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR TRAINING THE MODEL\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR SPLITING AND EVALUATING THE MODEL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLING THE ENCODER FOR ENCODING\n",
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES FOR ENCODING \n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT BEST FEATURE FOR TRAINING\n",
    "selected_features = [\n",
    "    \"VisitYear\",        \n",
    "    \"VisitMonth\",       \n",
    "    \"VisitModeName\",    \n",
    "    \"AttractionId\",     \n",
    "    \"Attraction\",      \n",
    "    \"AttractionType\",  \n",
    "    \"CountryId\",        \n",
    "    \"RegionId\"          \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING CATEGORICAL DATA TO NUMERIC DATA\n",
    "categorical_features = [\"VisitModeName\", \"AttractionType\"]\n",
    "\n",
    "df_selected = Tourism_df[selected_features + [\"Rating\"]].copy()\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "encoded_features = ohe.fit_transform(df_selected[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out(categorical_features))\n",
    "\n",
    "bool_cols = df_selected.select_dtypes(include=[\"bool\"]).columns\n",
    "df_selected[bool_cols] = df_selected[bool_cols].astype(int)\n",
    "\n",
    "target_enc = TargetEncoder()\n",
    "df_selected[\"Attraction\"] = target_enc.fit_transform(df_selected[\"Attraction\"], df_selected[\"Rating\"])\n",
    "\n",
    "df_selected = df_selected.drop(columns=categorical_features)\n",
    "df_selected = pd.concat([df_selected, encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNING X FOR FEATURE AND Y FOR TARGET\n",
    "X = df_selected.drop(columns=[\"Rating\"])\n",
    "y = df_selected[\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE CONVERTED \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT THE BIG NUMERIC TO SMALL \n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE DATA FOR TRAINING AND TESTING\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE THE SKLEARN LIBRARY\n",
    "pip install --upgrade xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE DECISION TREE REGRESSOR\n",
    "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE DC TREE MODEL \n",
    "dt_pred = np.round(dt_pred).astype(int)\n",
    "dt_pred = np.clip(dt_pred, 1, 5) \n",
    "\n",
    "dt_mae = mean_absolute_error(y_test, dt_pred)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, dt_pred))\n",
    "\n",
    "print(f\"Decision Tree Regressor → MAE: {dt_mae}, RMSE: {dt_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE RANDOM FOREST REGRESSION MODEL\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE RF MODEL \n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred = np.round(rf_pred).astype(int)\n",
    "rf_pred = np.clip(rf_pred, 1, 5) \n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "print(f\"Random Forest Regressor → MAE: {rf_mae}, RMSE: {rf_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE RANDOM FOREST WITH RANDOMIZEDSEARCHCV HYPERPARAMETER TUNNING\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=5, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE TUNED RF MODEL \n",
    "rf_pred = best_rf.predict(X_test)\n",
    "rf_pred = np.round(rf_pred).astype(int)\n",
    "rf_pred = np.clip(rf_pred, 1, 5) \n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "print(f\"Random Forest Regressor → MAE: {rf_mae}, RMSE: {rf_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE XGBOOST REGRESSOR MODEL\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE THE XGBOOST MODEL\n",
    "y_pred_xgb = model.predict(X_test)\n",
    "\n",
    "dt_pred = np.round(y_pred_xgb).astype(int)\n",
    "dt_pred = np.clip(dt_pred, 1, 5) \n",
    "print(dt_pred)\n",
    "\n",
    "dt_mae = mean_absolute_error(y_test, dt_pred)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, dt_pred))\n",
    "\n",
    "print(f\"Xgboost Regressor → MAE: {dt_mae}, RMSE: {dt_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE XGBOOST WITH RANDOMIZEDSEARCHCV HYPERPARAMETER TUNNING\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=param_grid, n_iter=20, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE THE TUNED XGBOOST MODEL\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"XGBoost Regressor (Tuned) → MAE: {mae:.4f}, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING LIGHTGBM MODEL\n",
    "import lightgbm as lgb\n",
    "lgb_model = lgb.LGBMRegressor(boosting_type='gbdt', \n",
    "                               n_estimators=200, \n",
    "                               learning_rate=0.1, \n",
    "                               max_depth=7, \n",
    "                               subsample=0.8, \n",
    "                               colsample_bytree=0.8, \n",
    "                               random_state=42)\n",
    "\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE THE LIGHTGBM MODEL\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"LightGBM Regressor → MAE: {mae:.4f}, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING JOBJIB TO SAVE THE MODEL\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE ENCODER\n",
    "joblib.dump(target_enc, r\"D:\\TRANSACTION PROJECT\\TARGET ENCODING RATING.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE SCALER \n",
    "joblib.dump(scaler, r\"D:\\TRANSACTION PROJECT\\STANDARD SCALAR RATING.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING ONE HOT ENCODER\n",
    "joblib.dump(ohe, r\"D:\\TRANSACTION PROJECT\\ONE HOT ENCODING RATING.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE BEST MODEL(TUNED XGBOOST)\n",
    "joblib.dump(best_xgb, r\"D:\\TRANSACTION PROJECT\\BEST MODEL FOR TOURISM.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
